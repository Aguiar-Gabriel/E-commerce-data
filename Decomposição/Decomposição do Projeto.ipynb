{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4089ed88",
   "metadata": {},
   "source": [
    "# Decomposição do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a5e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fe2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/gabri/Downloads/ecommerce_dataset_us.csv', sep='\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c147d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 28.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39364ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>541909.000000</td>\n",
       "      <td>541909.000000</td>\n",
       "      <td>406829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.552250</td>\n",
       "      <td>4.611114</td>\n",
       "      <td>15287.690570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>218.081158</td>\n",
       "      <td>96.759853</td>\n",
       "      <td>1713.600303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>-11062.060000</td>\n",
       "      <td>12346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>15152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>16791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>38970.000000</td>\n",
       "      <td>18287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity      UnitPrice     CustomerID\n",
       "count  541909.000000  541909.000000  406829.000000\n",
       "mean        9.552250       4.611114   15287.690570\n",
       "std       218.081158      96.759853    1713.600303\n",
       "min    -80995.000000  -11062.060000   12346.000000\n",
       "25%         1.000000       1.250000   13953.000000\n",
       "50%         3.000000       2.080000   15152.000000\n",
       "75%        10.000000       4.130000   16791.000000\n",
       "max     80995.000000   38970.000000   18287.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e93317",
   "metadata": {},
   "source": [
    "**Passo 1: Limpeza de Outliers**\n",
    "\n",
    "-   Utilizar a biblioteca Seaborn para [visualizar os dados](https://experienceleague.adobe.com/docs/experience-platform/data-science-workspace/jupyterlab/eda-notebook.html?lang=pt-BR) (link para guia que mostra como utilizar EDA para identificar outliers/Nan's/etc) e identificar visualmente dados indesejados. (Valores negativos na quantidade e no preço. Número de itens e preços absurdos)\n",
    "-   Aplicar técnicas de limpeza de outliers, como a identificação por meio de boxplots e a remoção dos valores discrepantes dos dados.\n",
    "-   Avaliar os resultados da limpeza de outliers e verificar se os dados estão mais consistentes para análise.\n",
    "-   Espero encontrar valores a serem corrigidos com a EDA e plotar gráficos para antes e depois para mostrar o resultado da limpeza visualmente.\n",
    "\n",
    "**Passo 2: Análise de Correlação**\n",
    "-   [Por que utilizar a análise de correlação?](https://www.anodot.com/blog/correlation-analysis-in-data-analytics/) (Post de uma empresa que usa ML para detectar anomalias em negócios)\n",
    "-   Utilizar técnicas estatísticas para analisar a correlação entre os dados.\n",
    "-   Utilizar a biblioteca Seaborn para criar gráficos de dispersão e matriz de correlação para visualizar a relação entre as variáveis.\n",
    "-   Analisar os resultados e identificar quais variáveis estão mais correlacionadas entre si.\n",
    "-   Espero gerar conclusões de possíveis relacionamentos entre os dados de quantidade de compra e os preços.\n",
    "\n",
    "**Passo 3: Clusterização com base no tipo de compra**\n",
    "\n",
    "-   Utilizar técnicas de clusterização, como o algoritmo [K-means](https://developers.google.com/machine-learning/clustering/algorithm/advantages-disadvantages#:~:text=Guarantees%20convergence.,sizes%2C%20such%20as%20elliptical%20clusters.) (Vantagens e desvantagens do método Kmeans (Google Devs)), para agrupar os clientes em clusters com base no tipo de compra que realizam.\n",
    "-   Definir os critérios para classificar os clientes em grupos, como muitos itens, poucos itens, itens caros ou baratos.\n",
    "-   Utilizar a biblioteca Scikit-learn para implementar o algoritmo K-means e realizar a clusterização dos dados.\n",
    "-   Avaliar os resultados da clusterização e identificar os diferentes perfis de clientes.\n",
    "-   Espero definir meus clientes a partir de blocos claros e distintos.\n",
    "\n",
    "**Passo 4: Definição do Perfil Lucrativo do E-commerce**\n",
    "\n",
    "-   Analisar os clusters gerados e identificar o perfil de clientes mais lucrativo para o e-commerce.\n",
    "-   Definir critérios de seleção do perfil lucrativo, como volume de compras multiplicado pelo preço do item.\n",
    "-   Comparar os diferentes clusters e identificar qual perfil é mais interessante para o negócio.\n",
    "-   Quero calcular o valor médio que cada estilo de compra retorna para o ecommerce, e gerar conclusões que a equipe de marketing poderia focar em estimular x tipos de compra.\n",
    "\n",
    "**Passo 5: [Método do Cotovelo](https://medium.com/pizzadedados/kmeans-e-metodo-do-cotovelo-94ded9fdf3a9) (Explicação de como pode ser utilizado)**\n",
    "\n",
    "-   Utilizar o método do cotovelo para determinar o número ideal de clusters para a segmentação dos clientes.\n",
    "-   Implementar o método do cotovelo utilizando a biblioteca Scikit-learn para realizar a clusterização com diferentes números de clusters.\n",
    "-   Avaliar os resultados e identificar o número de clusters que apresenta o menor erro de clusterização.\n",
    "\n",
    "**Passo 6: Método de Davies-Bouldin**\n",
    "\n",
    "-   Utilizar o método de Davies-Bouldin para avaliar a qualidade da clusterização obtida com o número de clusters determinado pelo método do cotovelo.\n",
    "-   Implementar o método de Davies-Bouldin utilizando a biblioteca Scikit-learn para calcular o índice de Davies-Bouldin para cada cluster.\n",
    "-   Avaliar os resultados e verificar se a escolha do número de clusters foi adequada com base no valor do índice de Davies-Bouldin.\n",
    "\n",
    "**Passo 7: Análise de Variação das Populações**\n",
    "\n",
    "-   Utilizar o teste de [Shapiro](https://psicometriaonline.com.br/blog/o-que-e-o-teste-de-shapiro-wilk/#:~:text=O%20Teste%20de%20Shapiro-Wilk%20tem%20como%20objetivo%20avaliar%20se,usada%20para%20modelar%20fenômenos%20naturais.) para verificar a normalidade das distribuições das populações dos diferentes clusters obtidos. (Dependendo do resultado, utilizaremos testes estatísticos diferentes para comparar a semelhança entre as populações dos clusters.\n",
    "-   Implementar o teste de Shapiro utilizando a biblioteca Scipy para verificar a normalidade dos dados em cada cluster.\n",
    "-   Avaliar os resultados e identificar quais clusters apresentam distribuições normais e quais não apresentam.\n",
    "\n",
    "**Passo 8: Teste de  [Mann-Whitney U](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1120984/#:~:text=The%20Mann-Whitney%20(or%20Wilcoxon,data%20are%20not%20normally%20distributed.)**\n",
    "-   \"It is often presented as an alternative to a t test when the data are not normally distributed.\"\n",
    "-   Utilizar o teste de Mann-Whitney U para comparar as distribuições das populações dos diferentes clusters e verificar se há diferenças estatisticamente significativas entre eles.\n",
    "-   Implementar o teste de Mann-Whitney U utilizando a biblioteca Scipy para comparar as distribuições de cada par de clusters.\n",
    "-   Utilizar um nível de significância (alpha) de 0.05 para determinar se as diferenças entre as populações são estatisticamente significativas.\n",
    "-   Analisar os resultados dos testes de Mann-Whitney U e identificar quais pares de clusters apresentam diferenças estatisticamente significativas.\n",
    "\n",
    "**Passo 9: Avaliação dos Resultados**\n",
    "\n",
    "-   Analisar os resultados obtidos em todos os passos anteriores e avaliar se os objetivos do projeto foram alcançados.\n",
    "-   Verificar se os clusters obtidos são consistentes e se representam perfis de clientes lucrativos para o e-commerce.\n",
    "-   Interpretar os resultados dos testes estatísticos e verificar se as diferenças entre os clusters são estatisticamente significativas.\n",
    "-   Avaliar a viabilidade de implementar ações de negócio com base nos resultados obtidos, como estratégias de marketing direcionadas a perfis específicos de clientes.\n",
    "\n",
    "**Passo 10: Apresentação dos Resultados**\n",
    "\n",
    "-   Elaborar uma apresentação clara e objetiva dos resultados obtidos em um Jupyter Notebook.\n",
    "-   Utilizar Markdown para estruturar o documento e apresentar os resultados de forma organizada e de fácil compreensão.\n",
    "-   Incluir gráficos, tabelas e interpretações dos resultados para facilitar a compreensão dos principais achados do projeto.\n",
    "-   Revisar e aprovar a apresentação com o líder da equipe antes de finalizar a tarefa.\n",
    "-   Com a conclusão desses passos, espera-se ter um plano claro para lidar com a tarefa de decomposição do projeto, utilizando técnicas de visualização, análise de correlação, clusterização, métodos estatísticos e avaliação dos resultados. Isso permitirá economizar tempo, reduzir a quantidade de revisões e obter um plano consistente para a resolução do problema proposto no projeto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03ef1029",
   "metadata": {},
   "source": [
    "#### Referências bibliográficas:\n",
    "\n",
    "- Limpeza de Outliers: Página da adaboe mostrando tratamento de dados por meio da EDA. https://experienceleague.adobe.com/docs/experience-platform/data-science-workspace/jupyterlab/eda-notebook.html?lang=pt-BR\n",
    "\n",
    "- Análise de correlação: Post da Anodot mostrando a importância da análise de correlação. https://www.anodot.com/blog/correlation-analysis-in-data-analytics/\n",
    "\n",
    "- Clusterização com Kmeans: Post do developers google citando as vantagens e desvantagens de utilizar o kmeans. https://developers.google.com/machine-learning/clustering/algorithm/advantages-disadvantages#:~:text=Guarantees%20convergence.,sizes%2C%20such%20as%20elliptical%20clusters.\n",
    "\n",
    "- Como utilizar o método do cotovelo e seus motivos:\n",
    "https://medium.com/pizzadedados/kmeans-e-metodo-do-cotovelo-94ded9fdf3a9\n",
    "\n",
    "- Utilizações do método de shapiro:\n",
    "https://psicometriaonline.com.br/blog/o-que-e-o-teste-de-shapiro-wilk/#:~:text=O%20Teste%20de%20Shapiro-Wilk%20tem%20como%20objetivo%20avaliar%20se,usada%20para%20modelar%20fen%C3%B4menos%20naturais.\n",
    "\n",
    "- Mann-Withney U x T Student:\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1120984/#:~:text=The%20Mann-Whitney%20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
